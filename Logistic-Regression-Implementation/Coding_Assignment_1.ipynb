{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "45ab4aa1-1267-4752-a45f-9c28afd03768"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e8d4fe5-6d59-47be-a656-84c5be7d0b05"
   },
   "source": [
    "## Sigmoid Function\n",
    "Implement the `compute_sigmoid()` function, which computes the Sigmoid function value.\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "* **`z`** : \n",
    "  * A 2D numpy array of floats\n",
    "\n",
    "**Returns:**\n",
    "\n",
    "* Sigmoid value of **z** with the same shape as **z**\n",
    "<br><br>$\\hspace{20mm}{\\sigma(z)} = \\frac{1}{1+e^{-z}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c371755d-4e97-4041-9e8e-40fd4b76b423"
   },
   "outputs": [],
   "source": [
    "def compute_sigmoid(z):\n",
    "    #ADD YOUR CODE HERE\n",
    "    sigmoid_value = 1/(1+np.exp(-z))\n",
    "    return sigmoid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5623e755-0150-495e-a6a9-fd5d4403374f",
    "outputId": "9e03f441-e7b3-4e6a-914e-fe0ba17179df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8808 0.7311 0.0387 0.9999]\n",
      " [0.7311 0.5    0.9978 0.047 ]]\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE TEST CASE\n",
    "z = np.array([[2, 1, -3.213, 9.4], [1, 0, 6.1, -3.01]])\n",
    "sigmoid_value = compute_sigmoid(z)\n",
    "print(np.round(sigmoid_value, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e87480fb-3843-4ddc-af71-0eb661af7f4d"
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "[[0.8808 0.7311 0.0387 0.9999]\n",
    " [0.7311 0.5    0.9978 0.047 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e12053a-5767-46db-853b-754611e340d5"
   },
   "source": [
    "## Hypothesis Function in Logistic Regression\n",
    "Implement the `compute_hypothesis()` function, which computes\n",
    "the hypothesis value using vectorization.\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "* **`X`** : Design Matrix\n",
    "  * A 2D numpy array of shape (num of instances, num of features)\n",
    "\n",
    "* **`w`** : Parameters corresponding to each feature\n",
    "  * A 2D numpy array of shape (num of features, 1)\n",
    "\n",
    "* **`b`** :  Intercept value\n",
    "  * A float value\n",
    "\n",
    "\n",
    "**Returns:**\n",
    "\n",
    "* Hypothesis value for the given data\n",
    " * A 2D numpy array of shape (num of instances, 1) <br><br>$\\hspace{20mm}H = \\sigma(Xw+b)\\\\[0.1pt]$\n",
    "<br>$\\hspace{2cm}$(where $\\sigma$ represents the sigmoid function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e64ec88a-1b9d-4c37-a462-14cd75f88ae9"
   },
   "outputs": [],
   "source": [
    "def compute_hypothesis(X, w, b):\n",
    "    #ADD YOUR CODE HERE\n",
    "    z = np.dot(X, w) + b\n",
    "    H = compute_sigmoid(z)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49068b4b-3b26-40c7-98e2-39ff15df974b",
    "outputId": "b3b349a7-274c-440a-df96-940226fc953c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.172 0.948\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE TEST CASE\n",
    "X = np.array([[-5, 2.34, 7, 6], [6, 1.2, 0, 4]])\n",
    "b = 0.1\n",
    "w = np.array([[0.3], [-0.5], [-0.2], [0.4]])\n",
    "H = (np.round(compute_hypothesis(X, w, b),3)).squeeze()\n",
    "print(*H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4455adf6-10dc-485b-a418-6018d5ff7410"
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "0.172 0.948\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcb7b47a-5f80-44ad-9a72-0dd0d45719e0"
   },
   "source": [
    "## $L_2$ Regularized Cost Function\n",
    "Implement the `compute_L2_cost()` function, which computes\n",
    "the $L_2$ Regularized cost value in Logistic Regression.\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "* **`X`** : Design Matrix\n",
    "  * A 2D numpy array of shape (num of instances, num of features)\n",
    "\n",
    "* **`Y`** : Target values corresponding to each training instance in $X$\n",
    "  * A 2D numpy array of shape (num of instances, 1)\n",
    "\n",
    "* **`w`** : Parameters corresponding to each feature\n",
    "  * A 2D numpy array of shape (num of features, 1)\n",
    "\n",
    "* **`b`** :  Intercept value\n",
    "  * A float value\n",
    "\n",
    "* **`Lambda`** :  Regularization parameter($\\lambda$)\n",
    "  * A float value\n",
    "\n",
    "\n",
    "**Returns:**\n",
    "\n",
    "* $L_2$ Regularized cost value for the given data <br><br>$\\hspace{20mm}J_{w,b}(X)=\\frac{-1}{m}\\left [Y^Tlog(H)+(1-Y)^Tlog(1-H) \\right ]+ \\frac{\\lambda}{2m}w^Tw\\\\[0.1pt]$\n",
    "<br>$\\hspace{2cm}$(where $H$ is the Hypothesis value of $X$, and $m$ is the number of instances) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7f0588e1-b7e8-428b-97ff-341ed53ff050"
   },
   "outputs": [],
   "source": [
    "def compute_L2_cost(X, Y, w, b, Lambda):\n",
    "    #ADD YOUR CODE HERE\n",
    "    m = len(X)\n",
    "    H = compute_hypothesis(X, w, b)\n",
    "    regression_value = np.dot(Y.T, np.log(H)) + np.dot((1-Y).T, np.log(1-H))\n",
    "    regularization_value = (Lambda/(2*m)) * np.dot(w.T, w)\n",
    "    J = (-1/m * regression_value) + regularization_value\n",
    "    return np.squeeze(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc33cbcc-213f-4700-a7c7-d9ce1694f26f",
    "outputId": "293751f1-fd73-4cc0-bdca-ff45707caf14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE TEST CASE\n",
    "X = np.array([[-5, 2.34, 7, 6], [6, 1.2, 0, 4]])\n",
    "Y = np.array([[0], [1]])\n",
    "w = np.array([[0.3], [-0.5], [-0.2], [0.4]])\n",
    "b = 0.1\n",
    "Lambda = 0.1\n",
    "cost_value = np.round(compute_L2_cost(X, Y, w, b, Lambda),3)\n",
    "print(cost_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e50f8fd8-231e-4f11-bcd9-0cb98c2f6af3"
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "0.135\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "948c2675-d18d-4331-8792-4352fc97c01a"
   },
   "source": [
    "## Gradients of $L_2$ Regularized Cost Function\n",
    "Implement the `gradient_of_L2_cost()`, which computes\n",
    "the gradients of the $L_2$ regularized cost function in Logistic Regression.\n",
    "\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "* **`X`** : Design Matrix\n",
    "  * A 2D numpy array of shape (num of instances, num of features)\n",
    "\n",
    "* **`Y`** : Target values corresponding to each training instance in $X$\n",
    "  * A 2D numpy array of shape (num of instances, 1)\n",
    "\n",
    "* **`w`** : Parameters corresponding to each feature\n",
    "  * A 2D numpy array of shape (num of features, 1)\n",
    "\n",
    "* **`b`** :  Intercept value\n",
    "  * A float value\n",
    "\n",
    "* **`Lambda`** :  Regularization parameter($\\lambda$)\n",
    "  * A float value\n",
    "\n",
    "\n",
    "\n",
    "**Returns:**\n",
    "* Gradient of the cost function corresponding to the parameters of each feature.\n",
    " * A 2D numpy array of shape (num of features, 1)<br><br>$\\hspace{20mm}\\frac{dJ}{dw} = \\frac{1}{m}\\left [ X^T(H-Y) + \\lambda w\\right ]$<br><br>\n",
    "* Gradient corresponding to the intercept value\n",
    " * A float value<br><br>$\\hspace{20mm}\\frac{dJ}{db} = \\frac{1}{m}\\sum (H-Y) \\\\[0.1pt]  \\\\[0.1pt]$\n",
    "<br>$\\hspace{2cm}$(where $H$ is the Hypothesis value of $X$, and $m$ is the number of instances) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "da86ac9a-9155-483a-bd57-94feb8eb414d"
   },
   "outputs": [],
   "source": [
    "def gradient_of_L2_cost(X, Y, w, b, Lambda):\n",
    "    #ADD YOUR CODE HERE\n",
    "    m = len(X)\n",
    "    H = compute_hypothesis(X, w, b)\n",
    "    dw = 1/m * (np.dot(X.T,(H-Y)) + (Lambda * w))\n",
    "    db = 1/m * (np.sum(H-Y))\n",
    "    return dw, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf0f443c-9b82-4464-bcbb-749cd2dcdb54",
    "outputId": "b669daf2-a6e1-47e2-cd99-9f84f9d749f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.572 0.145 0.593 0.432\n",
      "0.06\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE TEST CASE\n",
    "X = np.array([[-5, 2.34, 7, 6], [6, 1.2, 0, 4]])\n",
    "Y = np.array([[0], [1]])\n",
    "w = np.array([[0.3], [-0.5], [-0.2], [0.4]])\n",
    "b = 0.1\n",
    "Lambda = 0.1\n",
    "dw, db = gradient_of_L2_cost(X, Y, w, b, Lambda)\n",
    "dw = np.round(dw.ravel(),3)\n",
    "print(*dw)\n",
    "print(np.round(db,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4b564e2-00b9-473e-94a5-9679e996275c"
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "-0.572 0.145 0.593 0.432\n",
    "0.06\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b5c704b-20ae-4146-b573-5691ffb6f75b"
   },
   "source": [
    "## Gradient Descent in $L_2$ Regularized Logistic Regression\n",
    "Compute the optimal parameter values using gradient descent.\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "* **`X`** : Design Matrix\n",
    "  * A 2D numpy array of shape (num of instances, num of features)\n",
    "\n",
    "* **`Y`** : Target values corresponding to each training instance in $X$\n",
    "  * A 2D numpy array of shape (num of instances, 1)\n",
    "\n",
    "* **`w`** : Initial parameters corresponding to each feature\n",
    "  * A 2D numpy array of shape (num of features, 1)\n",
    "\n",
    "* **`b`** :  Initial intercept value\n",
    "  * A float value\n",
    "\n",
    "* **`cost_diff_threshold`** : threshold value for the absolute cost difference to stop iterating in gradient descent (*Convergence Criteria*)\n",
    "  * A float value\n",
    "\n",
    "* **`learning_rate`** :  Learning rate($\\alpha$)\n",
    "  * A float value\n",
    "\n",
    "* **`Lambda`** :  Regularization parameter($\\lambda$)\n",
    "  * A float value\n",
    "\n",
    "**Returns:**\n",
    "* `w`: Optimal parameters of features($w$'s)\n",
    " * A 2D numpy array with the same shape as the argument $w$<br>\n",
    "$\\hspace{10mm}w = w - \\alpha \\frac{dJ}{dw}$<br><br>\n",
    "* `b`: Optimal intercept value<br>\n",
    "$\\hspace{20mm}b = b - \\alpha \\frac{dJ}{db}$<br><br>\n",
    "\n",
    "**NOTE:**\n",
    "* The gradient descent is said to be converged when the absolute value of the cost difference is less than the given threshold.\n",
    "* Stop iterating when the gradient descent starts to diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "30db5dcf-a1e5-463b-846b-d3ecb63853fa"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, w, b, cost_diff_threshold, learning_rate, Lambda):\n",
    "    #ADD YOUR CODE HERE\n",
    "    i = 0\n",
    "    costs = [compute_L2_cost(X, Y, w, b, Lambda)]\n",
    "    ws = [w]\n",
    "    bs = [b]\n",
    "    cost_diff = cost_diff_threshold + 1\n",
    "    while(abs(cost_diff) > cost_diff_threshold):\n",
    "      dw, db = gradient_of_L2_cost(X, Y, w, b, Lambda)\n",
    "      w = w - (learning_rate * dw)\n",
    "      b = b - (learning_rate * db)\n",
    "      costs.append(compute_L2_cost(X, Y, w, b, Lambda))\n",
    "      ws.append(w)\n",
    "      bs.append(bs)\n",
    "      cost_diff = costs[i+1] - costs[i]\n",
    "      if cost_diff > 0:\n",
    "        print(f\"Divergent at {i}\")\n",
    "        break\n",
    "      i = i + 1\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "304c520f-9c1c-4e3f-ac70-dd7758da7e83",
    "outputId": "f94d8b78-105b-4b7d-dcb1-39642441eb15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.654 -0.06 -0.399 -0.096\n",
      "1.616\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE TEST CASE\n",
    "X = np.array([[-5, 2.34, 7, 6], [6, 1.2, 0, 4]])\n",
    "Y = np.array([[0], [1]])\n",
    "w = np.array([[0.3], [-0.5], [-0.2], [0.4]])\n",
    "b = 0.1\n",
    "Lambda = 0.1\n",
    "cost_diff_threshold = 5e-10\n",
    "learning_rate = 0.01 \n",
    "w, b = gradient_descent(X, Y, w, b, cost_diff_threshold, learning_rate, Lambda)\n",
    "w = np.round(w.ravel(),3)\n",
    "print(*w)\n",
    "print(np.round(b,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2c29bee-840a-4aff-8111-c6dc3e9ba40d"
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "0.654 -0.06 -0.399 -0.096\n",
    "1.616\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc865f54-69b7-4a14-ab74-839e798fca47"
   },
   "source": [
    "## One-vs-Rest for Multi-Class Classification\n",
    "Implement the `one_vs_rest()` function, which uses the One-vs-Rest approach to compute the optimal parameters for each class in a Multi-Class Classification Problem using Logistic Regression.\n",
    "\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "* **`X`** : Design Matrix\n",
    "  * A 2D numpy array of shape (num of instances, num of features)\n",
    "\n",
    "* **`Y`** : Target values corresponding to each training instance in $X$\n",
    "  * A 2D numpy array of shape (num of instances, 1)\n",
    "\n",
    "* **`w`** : Initial parameters corresponding to each feature\n",
    "  * A 2D numpy array of shape (num of features, 1)\n",
    "\n",
    "* **`b`** :  Initial intercept value\n",
    "  * A float value\n",
    "\n",
    "* **`cost_diff_threshold`** : threshold value for the absolute cost difference to stop iterating in gradient descent (*Convergence Criteria*)\n",
    "  * A float value\n",
    "\n",
    "* **`learning_rate`** :  Learning rate($\\alpha$)\n",
    "  * A float value\n",
    "\n",
    "* **`Lambda`** :  Regularization parameter($\\lambda$)\n",
    "  * A float value\n",
    "\n",
    "\n",
    "\n",
    "**Returns:**\n",
    "* `classwise_params_dict`\n",
    " * A dict where the keys are the class labels and the values are the respective optimal parameters [$w$, $b$]<br>\n",
    "   * where $w$ is a 2D numpy array with the same shape as the argument $w$<br>\n",
    "   * $b$ is the optimal value of the intercept (float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "b107eafb-467b-4d7f-8e56-c5632d348a39"
   },
   "outputs": [],
   "source": [
    "def one_vs_rest(X, Y, w, b, cost_diff_threshold, learning_rate, Lambda):\n",
    "    #ADD YOUR CODE HERE\n",
    "    classes = np.unique(Y)\n",
    "    classes.sort()\n",
    "    classwise_params_dict = {}\n",
    "    for class_label in classes:\n",
    "        classes_y = np.where(class_label == Y,1,0)\n",
    "        optimal_w,optimal_b = gradient_descent(X, classes_y, w, b, cost_diff_threshold, learning_rate, Lambda)\n",
    "        classwise_params_dict[class_label] = [optimal_w, optimal_b]\n",
    "    return classwise_params_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7e2b451f-8843-4ac8-88c0-c2fa293c6040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label: 0\n",
      "w: 0.437 0.931 -1.732 -0.761\n",
      "b: 0.432\n",
      "class_label: 1\n",
      "w: -1.839 1.44 1.256 0.429\n",
      "b: 0.524\n",
      "class_label: 2\n",
      "w: -0.199 -2.117 1.287 0.558\n",
      "b: -1.374\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE TEST CASE\n",
    "X = np.array([[4.9, 3.0, 1.4, 0.2], [4.6, 3.4, 1.4, 0.3], [5.6, 3.0, 4.5, 1.5], [6.1, 3.0, 4.6, 1.4], [7.7, 2.6, 6.9, 2.3]])\n",
    "Y = np.array([[0], [0], [1], [1], [2]])\n",
    "w = np.array([[0.1], [0.1], [-0.1], [-0.1]])\n",
    "b = 0.1\n",
    "cost_diff_threshold = 1e-5\n",
    "learning_rate = 0.1\n",
    "Lambda = 0.1\n",
    "\n",
    "classwise_params_dict = one_vs_rest(X, Y, w, b, cost_diff_threshold, learning_rate, Lambda)\n",
    "\n",
    "classes = sorted(classwise_params_dict.keys())\n",
    "for class_label in classes:\n",
    "    print(\"class_label:\",class_label)\n",
    "    [w, b] = classwise_params_dict[class_label]\n",
    "    print(\"w:\", *np.round(w.ravel(),3))\n",
    "    print(\"b:\", np.round(b,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "488aadbe-e359-4a03-b560-fa1ed2115a37"
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "class_label: 0\n",
    "w: 0.437 0.931 -1.732 -0.761\n",
    "b: 0.432\n",
    "class_label: 1\n",
    "w: -1.839 1.44 1.256 0.429\n",
    "b: 0.524\n",
    "class_label: 2\n",
    "w: -0.199 -2.117 1.287 0.558\n",
    "b: -1.374\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "209d9de7-cf9d-4711-9bad-4a989d1ea6e8"
   },
   "source": [
    "## Prediction in One-vs-Rest Approach \n",
    "Implement the `predict_labels_in_one_vs_rest()` function, \n",
    "which predicts the class labels based on the optimal parameter values of each class learned using the One-vs-Rest approach.\n",
    "\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "* **`X`** : Design Matrix to predict the class labels for\n",
    "  * A 2D numpy array of shape (num of instances, num of features)\n",
    "\n",
    "* **`classwise_params_dict`**: A dict where the keys are the class labels(ints) and the values are the respective optimal parameters [$w$, $b$]<br>\n",
    "   * where $w$ is a 2D numpy array with the shape (num of features, 1)<br>\n",
    "   * $b$ is the optimal value of the intercept (float)\n",
    "\n",
    "\n",
    "\n",
    "**Returns:**\n",
    "\n",
    "* Predicted class labels of $X$\n",
    " * A 2D numpy array of shape (num of instances, 1)\n",
    " * If there is a tie among the class probabilities, predict the class label with the smallest value among the tied classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "a1bee541-6e1a-489e-9d48-af9a2dc9baac"
   },
   "outputs": [],
   "source": [
    "def predict_labels_in_one_vs_rest(X, classwise_params_dict):\n",
    "    #ADD YOUR CODE HERE\n",
    "    classes = sorted(classwise_params_dict.keys())\n",
    "    classes = np.array(classes)\n",
    "    hypothesis_values = np.zeros((len(classes), len(X)))\n",
    "    \n",
    "    for idx, classes_labels in enumerate(classes):\n",
    "        params = classwise_params_dict[classes_labels]\n",
    "        w = params[0]\n",
    "        b = params[1]\n",
    "        hypothesis_values[idx] = compute_hypothesis(X, w, b).ravel()\n",
    "        \n",
    "    # print(hypothesis_values)\n",
    "    predicted_idx = np.argmax(hypothesis_values, axis= 0).ravel()\n",
    "    # print(predicted_idx)\n",
    "    predicted = classes[predicted_idx]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "79eb9a37-409e-47e5-933d-be8696ec9e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 2 2 3\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE TEST CASE\n",
    "X = np.array([[4.9, 3.0, 1.4, 0.2], [4.6, 3.4, 1.4, 0.3], [5.6, 3.0, 4.5, 1.5], [6.1, 3.0, 4.6, 1.4], [7.7, 2.6, 6.9, 2.3]])\n",
    "\n",
    "classwise_params_dict = {1: [np.array([[ 0.43],[ 0.93],[-1.73 ],[-0.76]]), 0.43], \n",
    "                         2: [np.array([[-1.84 ],[ 1.42],[ 1.25],[ 0.43]]), 0.63],\n",
    "                         3: [np.array([[-0.22],[-2.07],[ 1.32],[ 0.56]]), -1.54]}\n",
    "\n",
    "predictions = predict_labels_in_one_vs_rest(X, classwise_params_dict)\n",
    "print(*predictions.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5757155-f2ea-45a2-a6d6-c1ec175a886a"
   },
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "1 1 2 2 3\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
