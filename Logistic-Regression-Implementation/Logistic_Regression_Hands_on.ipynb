{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression: Hands-on",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages"
      ],
      "metadata": {
        "id": "fmyRB_VFlr65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "85zlonPolfPe"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid Function \n",
        "\n",
        "Function can be represented as\n",
        "\n",
        "$\\hspace{20mm}{\\sigma(z)}$ = $\\frac{1}{1+e^-z}$"
      ],
      "metadata": {
        "id": "I-vCBQXflww0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## compute sigmoid value"
      ],
      "metadata": {
        "id": "sf-KZgwvoJnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sigmoid(z):\n",
        "  sigmoid_value = 1/(1 + np.exp(-z))\n",
        "  return sigmoid_value"
      ],
      "metadata": {
        "id": "1ObUXvXhmkpT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hypothesis Function\n",
        "\n",
        "$\\hspace{20mm}H$ = $\\sigma(Xw + b)$"
      ],
      "metadata": {
        "id": "VZrEY348nARm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_hypothesis(w, x, b):\n",
        "  z = np.dot(w,x) + b\n",
        "  h = compute_sigmoid(z)\n",
        "  return h"
      ],
      "metadata": {
        "id": "gTJMkGTAm_Ug"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Cost\n",
        "\n",
        "$\\hspace{20mm}J$ = $\\frac{-1}{m}(Y^Tlog(H) + (1-Y)log(1-H))$"
      ],
      "metadata": {
        "id": "Ih7zrjN1oBH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(w, x, b,  y):\n",
        "  h = compute_hypothesis(w, x, b)\n",
        "  m = len(x)\n",
        "  j = (-1/m) * (np.dot(y.T, np.log(h)) + np.dot((1-y).T, (1-h)))\n",
        "  return j"
      ],
      "metadata": {
        "id": "l9o-0bdcoAW6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Cost\n",
        "\n",
        "\n",
        "\n",
        "$\\hspace{20mm}\\frac{dJ}{db}$ = $\\frac{1}{m}\\sum(H-Y)$\n",
        "\n",
        "\n",
        "<br>$\\hspace{20mm}\\frac{dJ}{dw}$ = $\\frac{1}{m}(X^T(H-Y))$\n"
      ],
      "metadata": {
        "id": "POtt3p17p1Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_cost(w, x, b, y):\n",
        "  h = compute_hypothesis(w, x, b)\n",
        "  m = len(x)\n",
        "  diff = h-y\n",
        "  db = (1/m) * (np.sum(diff))\n",
        "  dw = (1/m) * (np.dot(x.T, diff))\n",
        "  return dw, db\n"
      ],
      "metadata": {
        "id": "ylQW82_MptAG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Function\n",
        "\n",
        "$\\hspace{5mm}while( NotConverge)$ {\n",
        "<br>\n",
        "<br>\n",
        "$\\hspace{20mm} b = b - \\alpha \\frac{dJ}{db}$\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "$\\hspace{20mm} w = w - \\alpha \\frac{dJ}{dw}$\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "CCub_yKtr8Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_function(w, x, b, y, cost_diff_threshold, learning_rate):\n",
        "  i = 0\n",
        "  costs = [compute_cost(w, x, b, y)]\n",
        "  ws = [w]\n",
        "  bs = [b]\n",
        "  cost_diff = cost_diff_threshold+1\n",
        "  while(abs(cost_diff) > cost_diff_threshold):\n",
        "    dw, db = gradient_descent_cost(w, x, b, y)\n",
        "    w = w - (learning_rate* dw)\n",
        "    b = b - (learning_rate * db)\n",
        "    ws.append(w)\n",
        "    bs.append(b)\n",
        "    costs.append(compute_cost(w, x, b, y))\n",
        "\n",
        "    if cost_diff > 0:\n",
        "      print(\"Diverging case\")\n",
        "      print(i)\n",
        "      break\n",
        "    i = i + 1\n",
        "  return np.array(ws), np.array(bs), np.array(costs)"
      ],
      "metadata": {
        "id": "yULsJVxMri3e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_5qa9YOtWUq"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}